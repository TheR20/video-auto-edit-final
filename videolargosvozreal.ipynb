{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulo = \"¿El xmen no binario?, \"\n",
    "titulo_texto = \"\"\n",
    "nombre_descargado = \"video29.mp4\" \n",
    "seleccion_voz = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerias y rutas\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from googletrans import Translator\n",
    "from TTS.api import TTS\n",
    "import moviepy.editor as mp\n",
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip, TextClip, CompositeVideoClip\n",
    "import moviepy.editor as mpe\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import whisper\n",
    "from IPython.display import Audio, display\n",
    "import pyrubberband\n",
    "import os\n",
    "import gc\n",
    "from pydub import AudioSegment\n",
    "import imageio\n",
    "import random\n",
    "\n",
    "nombre_audio = \"\"\n",
    "nombre_gifiz = \"\"\n",
    "nombre_gifcen = \"\"\n",
    "nombre_gifder = \"\"\n",
    "\n",
    "if seleccion_voz == 1 :\n",
    "    nombre_audio = \"goth.wav\"\n",
    "    nombre_gifiz = \"//monos//bonitaiz.gif\"\n",
    "    nombre_gifcen = \"//monos//bonitacen.gif\"\n",
    "    nombre_gifder = \"//monos//bonitader.gif\"\n",
    "elif seleccion_voz == 2:\n",
    "    nombre_audio = \"audio_ing_resumen.wav\"\n",
    "    nombre_gifiz = \"//monos//gatomostacho1.gif\"\n",
    "    nombre_gifcen = \"//monos//gatomostacho2.gif\"\n",
    "    nombre_gifder = \"//monos//gatomostacho3.gif\"\n",
    "elif seleccion_voz == 3:\n",
    "    nombre_audio = \"shado.wav\"\n",
    "    nombre_gifiz = \"//monos//peloniz.gif\"\n",
    "    nombre_gifcen = \"//monos//peloncen.gif\"\n",
    "    nombre_gifder = \"//monos//pelonder.gif\"\n",
    "elif seleccion_voz == 4: \n",
    "    nombre_audio = \"ukyo.wav\"\n",
    "    nombre_gifiz = \"//monos//coleiz.gif\"\n",
    "    nombre_gifcen = \"//monos//colecer.gif\"\n",
    "    nombre_gifder = \"//monos//coleder.gif\"\n",
    "elif seleccion_voz == 5:\n",
    "    nombre_audio = \"jira.wav\"\n",
    "    nombre_gifiz = \"//monos//rubiz.gif\"\n",
    "    nombre_gifcen = \"//monos//rubcen.gif\"\n",
    "    nombre_gifder = \"//monos//rubder.gif\"\n",
    "elif seleccion_voz == 6:\n",
    "    nombre_audio = \"bonita.wav\"\n",
    "    nombre_gifiz = \"//monos//bonitaiz.gif\"\n",
    "    nombre_gifcen = \"//monos//bonitacen.gif\"\n",
    "    nombre_gifder = \"//monos//bonitader.gif\"\n",
    "elif seleccion_voz == 7:\n",
    "    nombre_audio = \"boni.wav\"\n",
    "    nombre_gifiz = \"//monos//roryiz.gif\"\n",
    "    nombre_gifcen = \"//monos//rorycen.gif\"\n",
    "    nombre_gifder = \"//monos//roryder.gif\"\n",
    "\n",
    "display(seleccion_voz)\n",
    "display(nombre_audio)\n",
    "\n",
    "\n",
    "rollitas = [\"beach\",\"docerola\",\"final\",\"funkcarioca\",\"hotlanda\",\"huasteco\",\"intro\",\n",
    "            \"mariachi\",\"oaxaca\",\"parade\",\"shake\",\"skyline\",\"takes\",\"wood\"]\n",
    "\n",
    "ruta_carpeta_principal = \"C://Users//R20//Desktop//videostraduccidos//\"\n",
    "ruta_carpeta_audios_esp = \"audios_creados//audio_esp_resumen.wav\"\n",
    "ruta_carpeta_audios_ing = \"audios_creados//\" + nombre_audio\n",
    "ruta_carpeta_audios_fin = \"audios_creados//audio_fin_resumen.wav\"\n",
    "ruta_carpeta_con_musica = \"audios_creados//audio_fin_musica.wav\"\n",
    "temporales = \"audios_creados//temporales//\"\n",
    "musica = \"audios_creados//musica//\"\n",
    "ruta_carpeta_videofin = \"videos_creados//\" + nombre_descargado\n",
    "ruta_carpeta_videofin_editado = \"videos_creados//finales\" + nombre_descargado\n",
    "nombre_video = \"videos_descargados//\" + nombre_descargado\n",
    "\n",
    "rutaVideo = ruta_carpeta_principal + nombre_video\n",
    "ruta_musica =  ruta_carpeta_principal + musica\n",
    "ruta_video_final_editado = ruta_carpeta_principal + ruta_carpeta_videofin_editado\n",
    "rutaAudioIngles = ruta_carpeta_principal + ruta_carpeta_audios_ing\n",
    "rutaAudioGenerado =  ruta_carpeta_principal + ruta_carpeta_audios_esp\n",
    "ruta_audios_temporales = ruta_carpeta_principal + temporales\n",
    "rutaAudioGeneradoNuevaVelocidad = ruta_carpeta_principal + ruta_carpeta_audios_fin\n",
    "rutaAudioGeneradoMusicaFondo = ruta_carpeta_principal +ruta_carpeta_con_musica\n",
    "ruta_video_final = ruta_carpeta_principal + ruta_carpeta_videofin\n",
    "ruta_imagenes = ruta_carpeta_principal + \"imagenes//\"\n",
    "ruta_audio = \"C://Users//R20//Desktop//videostraduccidos//audios_creados//audio_con_voz.wav\"\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poner musica de fondo\n",
    "\n",
    "random_number = np.random.randint(0, 14)\n",
    "# Cargar los audios\n",
    "audio = AudioSegment.from_wav(ruta_audio)\n",
    "music = AudioSegment.from_wav(ruta_musica + rollitas[random_number] + \".wav\")\n",
    "\n",
    "max_amplitude = audio.max_dBFS\n",
    "max_music = music.max_dBFS\n",
    "display(max_amplitude)\n",
    "display(max_music)\n",
    "display(str(random_number) + \" - \" + str(rollitas[random_number]))\n",
    "\n",
    "# Adjust the volume of the music (optional)\n",
    "if(max_amplitude <= -1):\n",
    "    audio_scaled = audio - .50\n",
    "    display(\"holi\")\n",
    "music_scaled = music - 25\n",
    "\n",
    "# Overlay the audio and music\n",
    "audio_mixed = audio.overlay(music_scaled)\n",
    "\n",
    "# Save the mixed audio\n",
    "audio_mixed.export(rutaAudioGeneradoMusicaFondo, format=\"wav\")\n",
    "\n",
    "audio_widget = Audio(filename=rutaAudioGeneradoMusicaFondo, autoplay=False)\n",
    "display(audio_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Termine de poner los gifs'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Termine de generar el texto del audio\n",
      "Moviepy - Building video C://Users//R20//Desktop//videostraduccidos//videos_creados//finalesvideo29.mp4.\n",
      "MoviePy - Writing audio in finalesvideo29TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video C://Users//R20//Desktop//videostraduccidos//videos_creados//finalesvideo29.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C://Users//R20//Desktop//videostraduccidos//videos_creados//finalesvideo29.mp4\n",
      "Moviepy - Building video C://Users//R20//Desktop//videostraduccidos////videos_creados//finales//video_finaloso.mp4.\n",
      "MoviePy - Writing audio in video_finalosoTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video C://Users//R20//Desktop//videostraduccidos////videos_creados//finales//video_finaloso.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C://Users//R20//Desktop//videostraduccidos////videos_creados//finales//video_finaloso.mp4\n"
     ]
    }
   ],
   "source": [
    "#videos individuales, largo, gif y subtitulado.\n",
    "numero_audios = 0\n",
    "video = None \n",
    "\n",
    "gifs_clips = []\n",
    "for filename in os.listdir(ruta_audios_temporales):\n",
    "     if filename.endswith((\"wav\")):\n",
    "         numero_audios +=1\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "def animacion_lateral(image,iteraciones_for,n_segundos,n_frames,duration_original):\n",
    "    # Estirar la imagen (ejemplo: duplicar su ancho)\n",
    "        image = image.resize((image.width , image.height ))\n",
    "\n",
    "        # Convertir a formato compatible con OpenCV\n",
    "        image_opencv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGRA)\n",
    "\n",
    "        # Crear la animación\n",
    "        alto, ancho, _ = image_opencv.shape\n",
    "        if iteraciones_for % 2 == 0:\n",
    "            matriz_transformacion = np.array([[2, 0, -image.width], [0, 1, 1]], dtype=np.float32)\n",
    "        else:\n",
    "            matriz_transformacion = np.array([[2, 0, 1], [0, 1, 1]], dtype=np.float32)\n",
    "        frames = []\n",
    "        pixeles_por_segundo = image.width / n_segundos\n",
    "        pixeles_por_frame = pixeles_por_segundo/n_frames\n",
    "        \n",
    "        for i in range(int(n_segundos*n_frames)):\n",
    "            imagen_transformada = cv2.warpAffine(image_opencv, matriz_transformacion, (ancho, alto))\n",
    "            # Convertir de BGR a RGB para mantener los colores originales\n",
    "            imagen_transformada = cv2.cvtColor(imagen_transformada, cv2.COLOR_BGRA2RGB)\n",
    "            frames.append(imagen_transformada)\n",
    "            if iteraciones_for % 2 == 0:\n",
    "                matriz_transformacion[0, 2] += pixeles_por_frame\n",
    "            else:\n",
    "                matriz_transformacion[0, 2] -= pixeles_por_frame\n",
    "\n",
    "        # Crear el clip de video con la animación\n",
    "        videok = mpe.ImageSequenceClip(frames, fps=30).set_duration(duration_original / 1.5)\n",
    "        return videok\n",
    "def animacion_zoom(duration_original,fr,imagen,iteraciones_for):\n",
    "    image = imageio.imread(imagen)\n",
    "    image_opencv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGRA)\n",
    "    n_frames = int(duration_original * fr)\n",
    "    alto, ancho, _ = image.shape\n",
    "    frames = []\n",
    "    # Calcular la escala inicial y final para que la animación dure todo el tiempo del video\n",
    "    if iteraciones_for % 2 == 0:\n",
    "        escala_inicial = 1\n",
    "        escala_final = 2\n",
    "    else:\n",
    "        escala_inicial = 2\n",
    "        escala_final = 1\n",
    "\n",
    "    for i in range(n_frames):\n",
    "        # Calcular la escala actual en función del progreso del video\n",
    "        progreso = i / n_frames\n",
    "        escala_actual = escala_inicial + (escala_final - escala_inicial) * progreso\n",
    "        \n",
    "        # Aplicar la transformación de escala\n",
    "        matriz_transformacion = cv2.getRotationMatrix2D((ancho/2, alto/2), 0, escala_actual)\n",
    "        imagen_transformada = cv2.warpAffine(image, matriz_transformacion, (ancho, alto))\n",
    "        \n",
    "        # Crear el borde negro para mantener el tamaño del video\n",
    "        borde_negro = np.zeros((imagen_transformada.shape[0], 10, 4), dtype=np.uint8)\n",
    "        imagen_con_borde = np.concatenate((imagen_transformada, borde_negro), axis=1)\n",
    "        frames.append(imagen_con_borde)\n",
    "\n",
    "    # Crear el clip de video con la secuencia de imágenes y establecer la duración\n",
    "    clip = mpe.ImageSequenceClip(frames, fps=fr).set_duration(duration_original / 1.5)\n",
    "    return clip\n",
    "\n",
    "def generar_videos_individuales():\n",
    "    display(numero_audios)\n",
    "    iteraciones_for = 2\n",
    "    n_frames = 30\n",
    "    random_anterior = 0\n",
    "    textos_separados= [\"\",\"\",\"Los mejores noodles\"]\n",
    "    for y in range(numero_audios):\n",
    "        ruta_audio_for = ruta_audios_temporales + \"temporal\" + str(y) + \".wav\"\n",
    "        ruta_imagen_for = ruta_imagenes + str(y+1)+ \".png\"\n",
    "        y_generated, sr_generated = librosa.load(ruta_audio_for)\n",
    "        duration_original = len(y_generated) / sr_generated\n",
    "        n_segundos = duration_original\n",
    "        iteraciones_for +=1\n",
    "        # Cargar la imagen\n",
    "        image = Image.open(ruta_imagen_for)\n",
    "\n",
    "        numero_random = random.randint(1, 4)\n",
    "        while numero_random == random_anterior:\n",
    "            numero_random = random.randint(1, 4)\n",
    "        random_anterior = numero_random\n",
    "        if numero_random == 1 or numero_random == 2:\n",
    "            video = animacion_lateral(image,numero_random,n_segundos,n_frames,duration_original)\n",
    "        else:\n",
    "            video = animacion_zoom(duration_original,n_frames,ruta_imagen_for,numero_random)\n",
    "        #video = clip.set_audio(mpe.AudioFileClip(ruta_audio_for))\n",
    "\n",
    "        video.fps = 30  # Ajusta el frame rate\n",
    "\n",
    "        video = video.resize((1920, 1080))  # Dimensiones Full HD\n",
    "        video_path = ruta_carpeta_principal + \"//videos_creados//finales//temporal\" + str(y) + \".mp4\"\n",
    "        if (((y + 1) % 3 == 0 or y == 0 ) and y != numero_audios) and y < len(textos_separados):\n",
    "            texto_completo = textos_separados[y]  # Texto que deseas mostrar\n",
    "            mitad = len(texto_completo) // 2\n",
    "            indice_espacio_mas_cercano = texto_completo.rfind(\" \", 0, mitad)  # Busca el espacio más cercano a la mitad\n",
    "            if indice_espacio_mas_cercano == -1:  # Si no se encontró ningún espacio, usar la mitad como punto de división\n",
    "                indice_espacio_mas_cercano = mitad\n",
    "            primera_parte = texto_completo[:indice_espacio_mas_cercano]\n",
    "            segunda_parte = texto_completo[indice_espacio_mas_cercano:].strip()\n",
    "            texto_con_salto_de_linea = f\"{primera_parte}\\n{segunda_parte}\"\n",
    "            fontsize = 65\n",
    "            posicion = (\"center\")\n",
    "            subtitle = mpe.TextClip(texto_con_salto_de_linea, fontsize=fontsize, font=\"ProtestStrike-Regular.ttf\", color='white', bg_color='black')\n",
    "            subtitle_clip = subtitle.set_pos(posicion).set_duration(duration_original / 1.5)\n",
    "            videos = mpe.CompositeVideoClip([video, subtitle_clip])\n",
    "            ffmpeg_params = [\"-vcodec\", \"h264_nvenc\"]  # Utiliza la GPU Nvidia para la codificación de video\n",
    "            videos.write_videofile(video_path, codec='libx264', ffmpeg_params=ffmpeg_params)\n",
    "            #videos.write_videofile(video_path)\n",
    "        else:\n",
    "            ffmpeg_params = [\"-vcodec\", \"h264_nvenc\"]  # Utiliza la GPU Nvidia para la codificación de video\n",
    "            video.write_videofile(video_path, codec='libx264', ffmpeg_params=ffmpeg_params)\n",
    "        \n",
    "            #video.write_videofile(video_path)\n",
    "        \n",
    "        del y_generated, sr_generated, duration_original, image, video\n",
    "        gc.collect()  # Llamar al recolector de basura de Python para liberar memoria adicional\n",
    "\n",
    "def video_largo():\n",
    "    video_concatenado = None\n",
    "    for y in range(numero_audios):\n",
    "        if(y != 0):\n",
    "            video_path_nuevo = ruta_carpeta_principal + \"//videos_creados//finales//temporal\" + str(y) + \".mp4\"\n",
    "            video_nuevo = mpe.VideoFileClip(video_path_nuevo)\n",
    "\n",
    "            # Concatenar los dos videos\n",
    "            if y == 1:\n",
    "                video_path_anterior = ruta_carpeta_principal + \"//videos_creados//finales//temporal\" + str(y-1) + \".mp4\"\n",
    "                video_anterior = mpe.VideoFileClip(video_path_anterior)\n",
    "                video_concatenado = mpe.concatenate_videoclips([video_anterior, video_nuevo])\n",
    "            else:\n",
    "                video_concatenado = mpe.concatenate_videoclips([video_concatenado, video_nuevo])\n",
    "        gc.collect()\n",
    "    # Agregar el audio al video concatenado\n",
    "    video_concatenado_with_audio = video_concatenado.set_audio(mpe.AudioFileClip(rutaAudioGeneradoMusicaFondo))\n",
    "\n",
    "    # Guardar el video concatenado con audio\n",
    "    video_concatenado_path = ruta_carpeta_principal + \"//videos_creados//finales//video_final.mp4\"\n",
    "    ffmpeg_params = [\"-vcodec\", \"h264_nvenc\"]  # Utiliza la GPU Nvidia para la codificación de video\n",
    "    video_concatenado_with_audio.write_videofile(video_concatenado_path, codec='libx264', ffmpeg_params=ffmpeg_params)\n",
    "    #video_concatenado_with_audio.write_videofile(video_concatenado_path)\n",
    "    # Liberar recursos\n",
    "    gc.collect()\n",
    "\n",
    "def poner_gif():\n",
    "        #Generar letreros en el video.\n",
    "    \n",
    "    #imagen = (mpe.ImageClip(ruta_imagenes + \"conocidas//patito.gif\")\n",
    "    imagen = (mpe.VideoFileClip(ruta_imagenes + \"conocidas//\"+nombre_gifiz, has_mask=True)         \n",
    "            .resize((800, 600))\n",
    "            .set_duration(8)\n",
    "                )  # Establecer la duración de la imagen a 3 segundos\n",
    "    imagen_final = (mpe.VideoFileClip(ruta_imagenes + \"conocidas//\"+nombre_gifcen, has_mask=True)         \n",
    "            .resize((800, 600))\n",
    "            .set_duration(8)\n",
    "                )\n",
    "    imagen_medio = (mpe.VideoFileClip(ruta_imagenes + \"conocidas//\"+nombre_gifder, has_mask=True)         \n",
    "            .resize((800, 600))\n",
    "            .set_duration(8)\n",
    "                )\n",
    "\n",
    "    random_number = np.random.randint(1, 5)\n",
    "    if random_number == 1:\n",
    "        clip_inicio = imagen.set_pos(\"center\")#((-250, 750))\n",
    "        clip_final = imagen_final.set_start(video.duration - 30).set_pos(\"center\")\n",
    "        clip_medio = imagen_medio.set_start(video.duration//2 - 1).set_pos(\"center\")\n",
    "    elif random_number == 2:\n",
    "        clip_inicio = imagen.set_pos(\"center\")\n",
    "        clip_final = imagen_medio.set_start(video.duration - 30).set_pos(\"center\")\n",
    "        clip_medio = imagen_final.set_start(video.duration//2 - 1).set_pos(\"center\")\n",
    "    elif random_number == 3:\n",
    "        clip_inicio = imagen_medio.set_pos(\"center\")\n",
    "        clip_final = imagen.set_start(video.duration - 30).set_pos(\"center\")\n",
    "        clip_medio = imagen_final.set_start(video.duration//2 - 1).set_pos(\"center\")\n",
    "    elif random_number == 4:\n",
    "        clip_inicio = imagen_final.set_pos(\"center\")\n",
    "        clip_final = imagen.set_start(video.duration - 30).set_pos(\"center\")\n",
    "        clip_medio = imagen_medio.set_start(video.duration//2 - 1).set_pos(\"center\")\n",
    "\n",
    "\n",
    "\n",
    "    superposicion = clip_inicio\n",
    "    superposicion2 = clip_final\n",
    "    superposicion3 = clip_medio\n",
    "\n",
    "\n",
    "    gifs_clips.append(superposicion)\n",
    "    gifs_clips.append(superposicion2)\n",
    "    gifs_clips.append(superposicion3)\n",
    "    display(\"Termine de poner los gifs\")\n",
    "    gc.collect()\n",
    "\n",
    "def poner_imagenes(nombre_imagen, inicio):\n",
    "    #Cargar la imagen y redimensionarla\n",
    "    imagen = (mpe.ImageClip(ruta_imagenes + \"conocidas//\"+nombre_imagen+\".png\")\n",
    "            .resize((400, 300))\n",
    "            .set_duration(1)\n",
    "            .set_start(inicio)\n",
    "            )  # Establecer la duración de la imagen a 3 segundos\n",
    "\n",
    "    ancho_video, alto_video = video.size\n",
    "\n",
    "    # Calcular las coordenadas del centro\n",
    "    x_centro = ancho_video / 2 - imagen.w / 2\n",
    "    y_centro = alto_video / 2 - imagen.h / 2\n",
    "\n",
    "    superposicion = imagen.set_pos((x_centro, y_centro))\n",
    "    return superposicion\n",
    "\n",
    "def obtener_texto_voz():\n",
    "    model = whisper.load_model(\"medium\")\n",
    "    result = model.transcribe(ruta_audio)\n",
    "\n",
    "    whisper_text = result[\"text\"]\n",
    "    whisper_language = result['language']\n",
    "\n",
    "    print(\"Termine de generar el texto del audio\")\n",
    "    whisper_text = whisper_text.replace('.', '. ').replace('?', '? ')\n",
    "    return  whisper_text\n",
    "\n",
    "def poner_subtitulos():\n",
    "    palabras_clave = [\"STEAM\",\"XBOX\",\"NINTENDO\",\"MARVEL\",\"UCM\",\"DC\",\"DCEU\",\"NETFLIX\",\"NICK\"]  # Ajusta según tus necesidades\n",
    "    whisper_text = obtener_texto_voz()\n",
    "\n",
    "    words = whisper_text.split()\n",
    "\n",
    "    # Group the words into pairs\n",
    "    #subtitle_lines = [' '.join(words[i:i+2]) for i in range(0, len(words), 2)]\n",
    "    subtitle_lines = []\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        if i + 1 < len(words) and words[i+1].strip() != '':\n",
    "            # Si el siguiente elemento de la lista no está vacío, unir las dos palabras con un espacio\n",
    "            subtitle_lines.append(' '.join([words[i], words[i+1]]))\n",
    "            i += 2\n",
    "        else:\n",
    "            # Si el siguiente elemento de la lista está vacío o es el último elemento, agregar solo la palabra actual\n",
    "            subtitle_lines.append(words[i])\n",
    "            i += 1\n",
    "\n",
    "    # Remove any empty strings from the list of subtitle lines\n",
    "    subtitle_lines = [line.strip() for line in subtitle_lines if line.strip()]\n",
    "\n",
    "    # Create a list to store the text clips\n",
    "    subtitle_clips = []\n",
    "    duration = video.duration / len(subtitle_lines)\n",
    "\n",
    "    # Initialize a variable to keep track of the current line number\n",
    "    line_number = 0\n",
    "    \n",
    "    # Create a TextClip for each subtitle line and add it to the list\n",
    "    for i, line in enumerate(subtitle_lines):\n",
    "        if any(palabra in line for palabra in palabras_clave):\n",
    "            # Encontrar la primera palabra clave en la línea\n",
    "            for palabra in palabras_clave:\n",
    "                if palabra in line:\n",
    "                    palabra_clave_encontrada = palabra\n",
    "                    break\n",
    "            display(palabra_clave_encontrada)      \n",
    "            superposicion = poner_imagenes(palabra_clave_encontrada, i * duration)\n",
    "            gifs_clips.append(superposicion)\n",
    "\n",
    "        # Increment the line number\n",
    "        line_number += 1\n",
    "    # Overlay the subtitle clips on the video clip\n",
    "    video_con_superposicion = CompositeVideoClip([video]+ gifs_clips)\n",
    "    video_con_superposicion = video_con_superposicion.set_duration(video.duration)\n",
    "    ffmpeg_params = [\"-vcodec\", \"h264_nvenc\"]  # Utiliza la GPU Nvidia para la codificación de video\n",
    "    video_con_superposicion.write_videofile(ruta_video_final_editado, codec='libx264', ffmpeg_params=ffmpeg_params)\n",
    "    #video_con_superposicion.write_videofile(ruta_video_final_editado)\n",
    "    gc.collect()\n",
    "\n",
    "def poner_intro():\n",
    "        video_path_nuevo = ruta_carpeta_principal + \"//videos_creados//intromorobos.mp4\"\n",
    "        video_nuevo = mpe.VideoFileClip(video_path_nuevo)\n",
    "        video_path_anterior = ruta_video_final_editado\n",
    "        video_anterior = mpe.VideoFileClip(video_path_anterior)\n",
    "        outro = ruta_carpeta_principal + \"//videos_creados//intromorobos.mp4\"\n",
    "        video_outro = mpe.VideoFileClip(outro)\n",
    "        video_concatenado = mpe.concatenate_videoclips([video_nuevo, video_anterior])\n",
    "        video_concatenad2 = mpe.concatenate_videoclips([video_concatenado, video_outro])\n",
    "        video_concatenado_path = ruta_carpeta_principal + \"//videos_creados//finales//video_finaloso.mp4\"\n",
    "        ffmpeg_params = [\"-vcodec\", \"h264_nvenc\"]  # Utiliza la GPU Nvidia para la codificación de video\n",
    "        video_concatenad2.write_videofile(video_concatenado_path, codec='libx264', ffmpeg_params=ffmpeg_params)\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "#generar_videos_individuales()\n",
    "#video_largo()\n",
    "video = mp.VideoFileClip(ruta_carpeta_principal + \"//videos_creados//finales//video_final.mp4\")\n",
    "poner_gif()\n",
    "poner_subtitulos()\n",
    "poner_intro()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
