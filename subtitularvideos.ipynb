{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import moviepy.editor as mp\n",
    "from moviepy.editor import TextClip, CompositeVideoClip\n",
    "\n",
    "nombre_video = \"venomvsvenom\"\n",
    "formato = \".mp4\"\n",
    "\n",
    "rutaVideo = \"C://Users//R20//Desktop//paisesvideo//shortnoticias//\" + nombre_video + formato\n",
    "ruta_video_final = \"C://Users//R20//Desktop//paisesvideo//subtitulados//\" + nombre_video + formato\n",
    "\n",
    "model = whisper.load_model(\"medium\")\n",
    "result = model.transcribe(rutaVideo)\n",
    "\n",
    "whisper_text = result[\"text\"]\n",
    "whisper_language = result['language']\n",
    "\n",
    "print(\"Audio text:\", whisper_text)\n",
    "\n",
    "whisper_text = whisper_text.replace('.', '. ').replace('?', '? ')\n",
    "\n",
    "video = mp.VideoFileClip(rutaVideo)\n",
    "\n",
    "words = whisper_text.split()\n",
    "\n",
    "# Group the words into pairs\n",
    "#subtitle_lines = [' '.join(words[i:i+2]) for i in range(0, len(words), 2)]\n",
    "subtitle_lines = []\n",
    "i = 0\n",
    "while i < len(words):\n",
    "    if i + 1 < len(words) and words[i+1].strip() != '':\n",
    "        # Si el siguiente elemento de la lista no está vacío, unir las dos palabras con un espacio\n",
    "        subtitle_lines.append(' '.join([words[i], words[i+1]]))\n",
    "        i += 2\n",
    "    else:\n",
    "        # Si el siguiente elemento de la lista está vacío o es el último elemento, agregar solo la palabra actual\n",
    "        subtitle_lines.append(words[i])\n",
    "        i += 1\n",
    "''' ota forma de cortar\n",
    "for i in range(0, len(words), 2):\n",
    "    if len(words[i]) > 8:\n",
    "        subtitle_lines.append(words[i])\n",
    "        subtitle_lines.append(words[i+1])\n",
    "    else:\n",
    "        subtitle_lines.append(' '.join([words[i], words[i+1]]))'''\n",
    "\n",
    "# Remove any empty strings from the list of subtitle lines\n",
    "subtitle_lines = [line.strip() for line in subtitle_lines if line.strip()]\n",
    "\n",
    "# Create a list to store the text clips\n",
    "subtitle_clips = []\n",
    "\n",
    "# Set the font size and duration for each subtitle line\n",
    "fontsize = 85\n",
    "# Register the font\n",
    "#font = ImageFont.truetype(\"Bubblegum.ttf\", fontsize)\n",
    "duration = video.duration / len(subtitle_lines)\n",
    "\n",
    "# Initialize a variable to keep track of the current line number\n",
    "line_number = 0\n",
    "\n",
    "# Subtitle Positioning:\n",
    "subtitle_position = ('center', 1250)  # Example position adjustment\n",
    "subtitle_position_shadow = (\"center\", 1238)\n",
    "# Create a TextClip for each subtitle line and add it to the list\n",
    "for i, line in enumerate(subtitle_lines):\n",
    "    line = line.upper()\n",
    "    if line_number % 3 == 0:\n",
    "        color = 'red'\n",
    "    elif line_number % 3 == 1:\n",
    "        color = 'yellow'\n",
    "    else:\n",
    "        color = 'white'\n",
    "\n",
    "\n",
    "\n",
    "    subtitle = TextClip(line, fontsize=fontsize,font=\"Super Disco Personal Use.ttf\", color=color)\n",
    "    subtitle_shadow = TextClip(line, fontsize=fontsize+3.9,font=\"Super Disco Personal Use.ttf\", color= \"black\")\n",
    "    subtitle_clip = subtitle_shadow.set_duration(duration).set_pos(subtitle_position_shadow).set_start(i * duration)\n",
    "    subtitle_clips.append(subtitle_clip)\n",
    "    subtitle_clip = subtitle.set_pos(subtitle_position).set_duration(duration).set_start(i * duration)\n",
    "    subtitle_clips.append(subtitle_clip)\n",
    "\n",
    "    # Increment the line number\n",
    "    line_number += 1\n",
    "\n",
    "# Overlay the subtitle clips on the video clip\n",
    "video_with_subtitles = CompositeVideoClip([video] + subtitle_clips)\n",
    "\n",
    "# Save the resulting clip\n",
    "video_with_subtitles.write_videofile(ruta_video_final)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to load audio: ffmpeg version 2024-02-19-git-0c8e64e268-essentials_build-www.gyan.dev Copyright (c) 2000-2024 the FFmpeg developers\r\n  built with gcc 12.2.0 (Rev10, Built by MSYS2 project)\r\n  configuration: --enable-gpl --enable-version3 --enable-static --pkg-config=pkgconf --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-zlib --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-sdl2 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxvid --enable-libaom --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-ffnvcodec --enable-nvdec --enable-nvenc --enable-dxva2 --enable-d3d11va --enable-libvpl --enable-libgme --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libtheora --enable-libvo-amrwbenc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-librubberband\r\n  libavutil      58. 39.100 / 58. 39.100\r\n  libavcodec     60. 39.101 / 60. 39.101\r\n  libavformat    60. 21.100 / 60. 21.100\r\n  libavdevice    60.  4.100 / 60.  4.100\r\n  libavfilter     9. 17.100 /  9. 17.100\r\n  libswscale      7.  6.100 /  7.  6.100\r\n  libswresample   4. 13.100 /  4. 13.100\r\n  libpostproc    57.  4.100 / 57.  4.100\r\n[in#0 @ 000001f77f044e80] Error opening input: No such file or directory\r\nError opening input file C://Users//R20//Desktop//videostraduccidos//videos_creadosvideo29.mp4.\r\nError opening input files: No such file or directory\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\whisper\\audio.py:58\u001b[0m, in \u001b[0;36mload_audio\u001b[1;34m(file, sr)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstdout\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Python39\\lib\\subprocess.py:528\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[1;32m--> 528\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[0;32m    529\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command '['ffmpeg', '-nostdin', '-threads', '0', '-i', 'C://Users//R20//Desktop//videostraduccidos//videos_creadosvideo29.mp4', '-f', 's16le', '-ac', '1', '-acodec', 'pcm_s16le', '-ar', '16000', '-']' returned non-zero exit status 4294967294.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m ruta_video_final \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC://Users//R20//Desktop//videostraduccidos//\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m nombre_video \u001b[38;5;241m+\u001b[39m formato\n\u001b[0;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m whisper\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedium\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrutaVideo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m whisper_text \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     17\u001b[0m whisper_language \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\whisper\\transcribe.py:133\u001b[0m, in \u001b[0;36mtranscribe\u001b[1;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[0m\n\u001b[0;32m    130\u001b[0m     decode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# Pad 30-seconds of silence to the input audio, for slicing\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m mel \u001b[38;5;241m=\u001b[39m \u001b[43mlog_mel_spectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_mels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_SAMPLES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m content_frames \u001b[38;5;241m=\u001b[39m mel\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m N_FRAMES\n\u001b[0;32m    135\u001b[0m content_duration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(content_frames \u001b[38;5;241m*\u001b[39m HOP_LENGTH \u001b[38;5;241m/\u001b[39m SAMPLE_RATE)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\whisper\\audio.py:140\u001b[0m, in \u001b[0;36mlog_mel_spectrogram\u001b[1;34m(audio, n_mels, padding, device)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(audio):\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(audio, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 140\u001b[0m         audio \u001b[38;5;241m=\u001b[39m \u001b[43mload_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     audio \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(audio)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\whisper\\audio.py:60\u001b[0m, in \u001b[0;36mload_audio\u001b[1;34m(file, sr)\u001b[0m\n\u001b[0;32m     58\u001b[0m     out \u001b[38;5;241m=\u001b[39m run(cmd, capture_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mstdout\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load audio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mdecode()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mfrombuffer(out, np\u001b[38;5;241m.\u001b[39mint16)\u001b[38;5;241m.\u001b[39mflatten()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m32768.0\u001b[39m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to load audio: ffmpeg version 2024-02-19-git-0c8e64e268-essentials_build-www.gyan.dev Copyright (c) 2000-2024 the FFmpeg developers\r\n  built with gcc 12.2.0 (Rev10, Built by MSYS2 project)\r\n  configuration: --enable-gpl --enable-version3 --enable-static --pkg-config=pkgconf --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-zlib --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-sdl2 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxvid --enable-libaom --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-ffnvcodec --enable-nvdec --enable-nvenc --enable-dxva2 --enable-d3d11va --enable-libvpl --enable-libgme --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libtheora --enable-libvo-amrwbenc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-librubberband\r\n  libavutil      58. 39.100 / 58. 39.100\r\n  libavcodec     60. 39.101 / 60. 39.101\r\n  libavformat    60. 21.100 / 60. 21.100\r\n  libavdevice    60.  4.100 / 60.  4.100\r\n  libavfilter     9. 17.100 /  9. 17.100\r\n  libswscale      7.  6.100 /  7.  6.100\r\n  libswresample   4. 13.100 /  4. 13.100\r\n  libpostproc    57.  4.100 / 57.  4.100\r\n[in#0 @ 000001f77f044e80] Error opening input: No such file or directory\r\nError opening input file C://Users//R20//Desktop//videostraduccidos//videos_creadosvideo29.mp4.\r\nError opening input files: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "import moviepy.editor as mp\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from moviepy.video.compositing.CompositeVideoClip import CompositeVideoClip\n",
    "from moviepy.video.VideoClip import TextClip\n",
    "import whisper\n",
    "\n",
    "nombre_video = \"video29\"\n",
    "formato = \".mp4\"\n",
    "\n",
    "rutaVideo = \"C://Users//R20//Desktop//videostraduccidos//videos_creados//\" + nombre_video + formato\n",
    "ruta_video_final = \"C://Users//R20//Desktop//videostraduccidos//\" + nombre_video + formato\n",
    "\n",
    "model = whisper.load_model(\"medium\")\n",
    "result = model.transcribe(rutaVideo)\n",
    "\n",
    "whisper_text = result[\"text\"]\n",
    "whisper_language = result['language']\n",
    "\n",
    "print(\"Audio text:\", whisper_text)\n",
    "\n",
    "whisper_text = whisper_text.replace('.', '. ').replace('?', '? ')\n",
    "\n",
    "video = VideoFileClip(rutaVideo)\n",
    "\n",
    "words = whisper_text.split()\n",
    "\n",
    "# Calculate the duration of each spoken word\n",
    "palabras_por_segundo = 3  # You may need to adjust this value based on your audio\n",
    "word_durations = [len(word) / palabras_por_segundo for word in words]\n",
    "\n",
    "# Create a list to store the subtitle clips\n",
    "subtitle_clips = []\n",
    "\n",
    "# Set the font size for the subtitle text\n",
    "fontsize = 85\n",
    "\n",
    "# Initialize variables for subtitle positioning and line number\n",
    "subtitle_position = ('center', 1250)\n",
    "subtitle_position_shadow = (\"center\", 1238)\n",
    "line_number = 0\n",
    "\n",
    "# Create subtitle clips aligned with spoken words\n",
    "current_time = 0\n",
    "for word, duration in zip(words, word_durations):\n",
    "    subtitle_clip = TextClip(word.upper(), fontsize=fontsize, font=\"Super Disco Personal Use.ttf\", color='white')\n",
    "    subtitle_clip = subtitle_clip.set_start(current_time).set_duration(duration).set_pos(subtitle_position)\n",
    "    subtitle_clip_shadow = TextClip(word.upper(), fontsize=fontsize+3.9, font=\"Super Disco Personal Use.ttf\", color='black')\n",
    "    subtitle_clip_shadow = subtitle_clip_shadow.set_start(current_time).set_duration(duration).set_pos(subtitle_position_shadow)\n",
    "    subtitle_clips.append(subtitle_clip_shadow)\n",
    "    subtitle_clips.append(subtitle_clip)\n",
    "    current_time += duration\n",
    "\n",
    "# Overlay the subtitle clips on the video clip\n",
    "video_with_subtitles = CompositeVideoClip([video] + subtitle_clips)\n",
    "\n",
    "# Save the resulting clip\n",
    "video_with_subtitles.write_videofile(ruta_video_final)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
