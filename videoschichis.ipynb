{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulo = \"¿El xmen no binario?, \"\n",
    "titulo_texto = \"\"\n",
    "nombre_descargado = \"video29.mp4\" \n",
    "seleccion_voz = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'audio_ing_resumen.wav'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Librerias y rutas\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from googletrans import Translator\n",
    "from TTS.api import TTS\n",
    "import moviepy.editor as mp\n",
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip, TextClip, CompositeVideoClip\n",
    "import moviepy.editor as mpe\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import whisper\n",
    "from IPython.display import Audio, display\n",
    "import pyrubberband\n",
    "import os\n",
    "import gc\n",
    "from pydub import AudioSegment\n",
    "import imageio\n",
    "import random\n",
    "\n",
    "nombre_audio = \"\"\n",
    "nombre_gifiz = \"\"\n",
    "nombre_gifcen = \"\"\n",
    "nombre_gifder = \"\"\n",
    "\n",
    "if seleccion_voz == 1 :\n",
    "    nombre_audio = \"goth.wav\"\n",
    "    nombre_gifiz = \"//monos//bonitaiz.gif\"\n",
    "    nombre_gifcen = \"//monos//bonitacen.gif\"\n",
    "    nombre_gifder = \"//monos//bonitader.gif\"\n",
    "elif seleccion_voz == 2:\n",
    "    nombre_audio = \"audio_ing_resumen.wav\"\n",
    "    nombre_gifiz = \"//monos//gatomostacho1.gif\"\n",
    "    nombre_gifcen = \"//monos//gatomostacho2.gif\"\n",
    "    nombre_gifder = \"//monos//gatomostacho3.gif\"\n",
    "elif seleccion_voz == 3:\n",
    "    nombre_audio = \"shado.wav\"\n",
    "    nombre_gifiz = \"//monos//peloniz.gif\"\n",
    "    nombre_gifcen = \"//monos//peloncen.gif\"\n",
    "    nombre_gifder = \"//monos//pelonder.gif\"\n",
    "elif seleccion_voz == 4: \n",
    "    nombre_audio = \"ukyo.wav\"\n",
    "    nombre_gifiz = \"//monos//coleiz.gif\"\n",
    "    nombre_gifcen = \"//monos//colecer.gif\"\n",
    "    nombre_gifder = \"//monos//coleder.gif\"\n",
    "elif seleccion_voz == 5:\n",
    "    nombre_audio = \"jira.wav\"\n",
    "    nombre_gifiz = \"//monos//rubiz.gif\"\n",
    "    nombre_gifcen = \"//monos//rubcen.gif\"\n",
    "    nombre_gifder = \"//monos//rubder.gif\"\n",
    "elif seleccion_voz == 6:\n",
    "    nombre_audio = \"bonita.wav\"\n",
    "    nombre_gifiz = \"//monos//bonitaiz.gif\"\n",
    "    nombre_gifcen = \"//monos//bonitacen.gif\"\n",
    "    nombre_gifder = \"//monos//bonitader.gif\"\n",
    "elif seleccion_voz == 7:\n",
    "    nombre_audio = \"boni.wav\"\n",
    "    nombre_gifiz = \"//monos//roryiz.gif\"\n",
    "    nombre_gifcen = \"//monos//rorycen.gif\"\n",
    "    nombre_gifder = \"//monos//roryder.gif\"\n",
    "\n",
    "display(seleccion_voz)\n",
    "display(nombre_audio)\n",
    "\n",
    "\n",
    "rollitas = [\"beach\",\"docerola\",\"final\",\"funkcarioca\",\"hotlanda\",\"huasteco\",\"intro\",\n",
    "            \"mariachi\",\"oaxaca\",\"parade\",\"shake\",\"skyline\",\"takes\",\"wood\"]\n",
    "\n",
    "ruta_carpeta_principal = \"C://Users//R20//Desktop//videostraduccidos//\"\n",
    "ruta_carpeta_audios_esp = \"audios_creados//audio_esp_resumen.wav\"\n",
    "ruta_carpeta_audios_ing = \"audios_creados//\" + nombre_audio\n",
    "ruta_carpeta_audios_fin = \"audios_creados//audio_fin_resumen.wav\"\n",
    "ruta_carpeta_con_musica = \"audios_creados//audio_fin_musica.wav\"\n",
    "temporales = \"audios_creados//temporales//\"\n",
    "musica = \"audios_creados//musica//\"\n",
    "ruta_carpeta_videofin = \"videos_creados//\" + nombre_descargado\n",
    "ruta_carpeta_videofin_editado = \"videos_creados//finales\" + nombre_descargado\n",
    "nombre_video = \"videos_descargados//\" + nombre_descargado\n",
    "\n",
    "rutaVideo = ruta_carpeta_principal + nombre_video\n",
    "ruta_musica =  ruta_carpeta_principal + musica\n",
    "ruta_video_final_editado = ruta_carpeta_principal + ruta_carpeta_videofin_editado\n",
    "rutaAudioIngles = ruta_carpeta_principal + ruta_carpeta_audios_ing\n",
    "rutaAudioGenerado =  ruta_carpeta_principal + ruta_carpeta_audios_esp\n",
    "ruta_audios_temporales = ruta_carpeta_principal + temporales\n",
    "rutaAudioGeneradoNuevaVelocidad = ruta_carpeta_principal + ruta_carpeta_audios_fin\n",
    "rutaAudioGeneradoMusicaFondo = ruta_carpeta_principal +ruta_carpeta_con_musica\n",
    "ruta_video_final = ruta_carpeta_principal + ruta_carpeta_videofin\n",
    "ruta_imagenes = ruta_carpeta_principal + \"imagenes//\"\n",
    "ruta_audio = \"C://Users//R20//Desktop//videostraduccidos//audios_creados//audio_con_voz.wav\"\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Termine de generar el texto del audio\n",
      "Translated text: Welcome to his favorite office with Dr. Morboso, today we will measure Yusuriha of Health's Paradise.And the funny thing about all this is that the perfect image we are always looking for them did not give them Crunchyroll in one of its posts in X. I do not say that any of its workers is a follower, but quite strange that just a perfect photo for the measurements.Already sponsors Crunchy and we measure everything new to the platform.But well, let's go to measurements now, to the important.The first is to get its height directly from the wiki of 1. 60, which gives us its underbust, the famous 69. 1 for the height of 1. 60. We take out the radius that are 11 centimeters and this helps us toThen be able to draw the scale and measure the thorax of 7 centimeters and the chest distance of 8. 3 centimeters.As you know, all these data are going directly to MC3000, our Chichis 3000 meter created in Python, which gives us our transverse section diagram to the necessary measurements, the mathematics necessary to give us the final result, which this time would be90. 2 centimeters.Really a chest not so big, but if they put it in perspective to a person of 1. 60, yes, it would look quite large.That is why when this measure subtracted with that of the Underbust, which was 69. 1, it would result in a Cup F or a double G. It probably still does not end up making sense because with 90 centimeters breasts sometimesIt is an F glass, sometimes a G glass, sometimes a Cup E, all this depends on both the size and size of the underbust.But do not worry, already in the following videos they will be watching version 2 that will make all this much easier to read.For now, tell me what this measure is, was what they expected?Do not forget that you can also send us the perfect photos through our Twitter or leave me here in the comments to those who want us to measure in the following video.His favorite doctor says goodbye, see you next time.\n",
      "Moviepy - Building video C://Users//R20//Desktop//videostraduccidos//videos_creados//finalesvideo29.mp4.\n",
      "MoviePy - Writing audio in finalesvideo29TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video C://Users//R20//Desktop//videostraduccidos//videos_creados//finalesvideo29.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C://Users//R20//Desktop//videostraduccidos//videos_creados//finalesvideo29.mp4\n"
     ]
    }
   ],
   "source": [
    "#videos individuales, largo, gif y subtitulado.\n",
    "numero_audios = 0\n",
    "video = None \n",
    "\n",
    "\n",
    "\n",
    "for filename in os.listdir(ruta_audios_temporales):\n",
    "     if filename.endswith((\"wav\")):\n",
    "         numero_audios +=1\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "def animacion_lateral(image,iteraciones_for,n_segundos,n_frames,duration_original):\n",
    "    # Estirar la imagen (ejemplo: duplicar su ancho)\n",
    "        image = image.resize((image.width , image.height ))\n",
    "\n",
    "        # Convertir a formato compatible con OpenCV\n",
    "        image_opencv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGRA)\n",
    "\n",
    "        # Crear la animación\n",
    "        alto, ancho, _ = image_opencv.shape\n",
    "        if iteraciones_for % 2 == 0:\n",
    "            matriz_transformacion = np.array([[2, 0, -image.width], [0, 1, 1]], dtype=np.float32)\n",
    "        else:\n",
    "            matriz_transformacion = np.array([[2, 0, 1], [0, 1, 1]], dtype=np.float32)\n",
    "        frames = []\n",
    "        pixeles_por_segundo = image.width / n_segundos\n",
    "        pixeles_por_frame = pixeles_por_segundo/n_frames\n",
    "        \n",
    "        for i in range(int(n_segundos*n_frames)):\n",
    "            imagen_transformada = cv2.warpAffine(image_opencv, matriz_transformacion, (ancho, alto))\n",
    "            # Convertir de BGR a RGB para mantener los colores originales\n",
    "            imagen_transformada = cv2.cvtColor(imagen_transformada, cv2.COLOR_BGRA2RGB)\n",
    "            frames.append(imagen_transformada)\n",
    "            if iteraciones_for % 2 == 0:\n",
    "                matriz_transformacion[0, 2] += pixeles_por_frame\n",
    "            else:\n",
    "                matriz_transformacion[0, 2] -= pixeles_por_frame\n",
    "\n",
    "        # Crear el clip de video con la animación\n",
    "        videok = mpe.ImageSequenceClip(frames, fps=30).set_duration(duration_original / 1.5)\n",
    "        return videok\n",
    "def animacion_zoom(duration_original,fr,imagen,iteraciones_for):\n",
    "    image = imageio.imread(imagen)\n",
    "    image_opencv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGRA)\n",
    "    n_frames = int(duration_original * fr)\n",
    "    alto, ancho, _ = image.shape\n",
    "    frames = []\n",
    "    # Calcular la escala inicial y final para que la animación dure todo el tiempo del video\n",
    "    if iteraciones_for % 2 == 0:\n",
    "        escala_inicial = 1\n",
    "        escala_final = 2\n",
    "    else:\n",
    "        escala_inicial = 2\n",
    "        escala_final = 1\n",
    "\n",
    "    for i in range(n_frames):\n",
    "        # Calcular la escala actual en función del progreso del video\n",
    "        progreso = i / n_frames\n",
    "        escala_actual = escala_inicial + (escala_final - escala_inicial) * progreso\n",
    "        \n",
    "        # Aplicar la transformación de escala\n",
    "        matriz_transformacion = cv2.getRotationMatrix2D((ancho/2, alto/2), 0, escala_actual)\n",
    "        imagen_transformada = cv2.warpAffine(image, matriz_transformacion, (ancho, alto))\n",
    "        \n",
    "        # Crear el borde negro para mantener el tamaño del video\n",
    "        borde_negro = np.zeros((imagen_transformada.shape[0], 10, 4), dtype=np.uint8)\n",
    "        imagen_con_borde = np.concatenate((imagen_transformada, borde_negro), axis=1)\n",
    "        frames.append(imagen_con_borde)\n",
    "\n",
    "    # Crear el clip de video con la secuencia de imágenes y establecer la duración\n",
    "    clip = mpe.ImageSequenceClip(frames, fps=fr).set_duration(duration_original / 1.5)\n",
    "    return clip\n",
    "\n",
    "def generar_videos_individuales():\n",
    "    display(numero_audios)\n",
    "    iteraciones_for = 2\n",
    "    n_frames = 30\n",
    "    random_anterior = 0\n",
    "    \n",
    "    for y in range(numero_audios):\n",
    "        ruta_audio_for = ruta_audios_temporales + \"temporal\" + str(y) + \".wav\"\n",
    "        ruta_imagen_for = ruta_imagenes + str(y+1)+ \".png\"\n",
    "        y_generated, sr_generated = librosa.load(ruta_audio_for)\n",
    "        duration_original = len(y_generated) / sr_generated\n",
    "        n_segundos = duration_original\n",
    "        iteraciones_for +=1\n",
    "        # Cargar la imagen\n",
    "        image = Image.open(ruta_imagen_for)\n",
    "\n",
    "        numero_random = random.randint(1, 4)\n",
    "        while numero_random == random_anterior:\n",
    "            numero_random = random.randint(1, 4)\n",
    "        random_anterior = numero_random\n",
    "        if numero_random == 1 or numero_random == 2:\n",
    "            video = animacion_lateral(image,numero_random,n_segundos,n_frames,duration_original)\n",
    "        else:\n",
    "            video = animacion_zoom(duration_original,n_frames,ruta_imagen_for,numero_random)\n",
    "        #video = clip.set_audio(mpe.AudioFileClip(ruta_audio_for))\n",
    "\n",
    "        video.fps = 30  # Ajusta el frame rate\n",
    "\n",
    "        video = video.resize((1920, 1080))  # Dimensiones Full HD\n",
    "        video_path = ruta_carpeta_principal + \"//videos_creados//finales//temporal\" + str(y) + \".mp4\"\n",
    "\n",
    "        ffmpeg_params = [\"-vcodec\", \"h264_nvenc\"]  # Utiliza la GPU Nvidia para la codificación de video\n",
    "        video.write_videofile(video_path, codec='libx264', ffmpeg_params=ffmpeg_params)\n",
    "        \n",
    "        #video.write_videofile(video_path)\n",
    "        \n",
    "        del y_generated, sr_generated, duration_original, image, video\n",
    "        print(\"termine los videos individuales\")\n",
    "        gc.collect()  # Llamar al recolector de basura de Python para liberar memoria adicional\n",
    "\n",
    "def video_largo():\n",
    "    video_concatenado = None\n",
    "    for y in range(numero_audios):\n",
    "        if(y != 0):\n",
    "            video_path_nuevo = ruta_carpeta_principal + \"//videos_creados//finales//temporal\" + str(y) + \".mp4\"\n",
    "            video_nuevo = mpe.VideoFileClip(video_path_nuevo)\n",
    "\n",
    "            # Concatenar los dos videos\n",
    "            if y == 1:\n",
    "                video_path_anterior = ruta_carpeta_principal + \"//videos_creados//finales//temporal\" + str(y-1) + \".mp4\"\n",
    "                video_anterior = mpe.VideoFileClip(video_path_anterior)\n",
    "                video_concatenado = mpe.concatenate_videoclips([video_anterior, video_nuevo])\n",
    "            else:\n",
    "                video_concatenado = mpe.concatenate_videoclips([video_concatenado, video_nuevo])\n",
    "        gc.collect()\n",
    "    # Agregar el audio al video concatenado\n",
    "    video_concatenado_with_audio = video_concatenado.set_audio(mpe.AudioFileClip(rutaAudioGeneradoMusicaFondo))\n",
    "\n",
    "    # Guardar el video concatenado con audio\n",
    "    video_concatenado_path = ruta_carpeta_principal + \"//videos_creados//finales//video_final.mp4\"\n",
    "    ffmpeg_params = [\"-vcodec\", \"h264_nvenc\"]  # Utiliza la GPU Nvidia para la codificación de video\n",
    "    video_concatenado_with_audio.write_videofile(video_concatenado_path, codec='libx264', ffmpeg_params=ffmpeg_params)\n",
    "    #video_concatenado_with_audio.write_videofile(video_concatenado_path)\n",
    "    # Liberar recursos\n",
    "    gc.collect()\n",
    "\n",
    "    \n",
    "        #Generar letreros en el video.\n",
    "    \n",
    "    #imagen = (mpe.ImageClip(ruta_imagenes + \"conocidas//patito.gif\")\n",
    "    imagen = (mpe.VideoFileClip(ruta_imagenes + \"conocidas//\"+nombre_gifiz, has_mask=True)         \n",
    "            .resize((800, 600))\n",
    "            .set_duration(8)\n",
    "                )  # Establecer la duración de la imagen a 3 segundos\n",
    "    imagen_final = (mpe.VideoFileClip(ruta_imagenes + \"conocidas//\"+nombre_gifcen, has_mask=True)         \n",
    "            .resize((800, 600))\n",
    "            .set_duration(8)\n",
    "                )\n",
    "    imagen_medio = (mpe.VideoFileClip(ruta_imagenes + \"conocidas//\"+nombre_gifder, has_mask=True)         \n",
    "            .resize((800, 600))\n",
    "            .set_duration(8)\n",
    "                )\n",
    "\n",
    "    random_number = np.random.randint(1, 5)\n",
    "    if random_number == 1:\n",
    "        clip_inicio = imagen.set_pos(\"center\")#((-250, 750))\n",
    "        clip_final = imagen_final.set_start(video.duration - 30).set_pos(\"center\")\n",
    "        clip_medio = imagen_medio.set_start(video.duration//2 - 1).set_pos(\"center\")\n",
    "    elif random_number == 2:\n",
    "        clip_inicio = imagen.set_pos(\"center\")\n",
    "        clip_final = imagen_medio.set_start(video.duration - 30).set_pos(\"center\")\n",
    "        clip_medio = imagen_final.set_start(video.duration//2 - 1).set_pos(\"center\")\n",
    "    elif random_number == 3:\n",
    "        clip_inicio = imagen_medio.set_pos(\"center\")\n",
    "        clip_final = imagen.set_start(video.duration - 30).set_pos(\"center\")\n",
    "        clip_medio = imagen_final.set_start(video.duration//2 - 1).set_pos(\"center\")\n",
    "    elif random_number == 4:\n",
    "        clip_inicio = imagen_final.set_pos(\"center\")\n",
    "        clip_final = imagen.set_start(video.duration - 30).set_pos(\"center\")\n",
    "        clip_medio = imagen_medio.set_start(video.duration//2 - 1).set_pos(\"center\")\n",
    "\n",
    "    superposicion = clip_inicio\n",
    "    superposicion2 = clip_final\n",
    "    superposicion3 = clip_medio\n",
    "\n",
    "    gifs_clips.append(superposicion)\n",
    "    gifs_clips.append(superposicion2)\n",
    "    gifs_clips.append(superposicion3)\n",
    "    display(\"Termine de poner los gifs\")\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "def obtener_texto_voz():\n",
    "    model = whisper.load_model(\"medium\")\n",
    "    result = model.transcribe(ruta_carpeta_principal + \"//videos_creados//finales//video_final.mp4\")\n",
    "\n",
    "    whisper_text = result[\"text\"]\n",
    "    whisper_language = result['language']\n",
    "\n",
    "    print(\"Termine de generar el texto del audio\")\n",
    "    whisper_text = whisper_text.replace('.', '. ').replace('?', '? ')\n",
    "    return  whisper_text\n",
    "\n",
    "\n",
    "def traduccion(resumen,idioma):\n",
    "    target_language = idioma\n",
    "    # Mapping between full names and ISO 639-1 codes\n",
    "    language_mapping = {'English': 'en', 'Spanish': 'es', 'Chinese (Simplified)': 'zh-cn', 'Japanese': 'ja'}\n",
    "    target_language_code = language_mapping[target_language]\n",
    "    translator = Translator()\n",
    "    whisper_language = translator.detect(resumen).lang\n",
    "    translated_text = translator.translate(resumen, src=whisper_language, dest=target_language_code).text\n",
    "    translated_text = titulo_texto + translated_text \n",
    "    print(\"Translated text:\", translated_text)\n",
    "    return translated_text\n",
    "\n",
    "def poner_subtitulos_eng(): \n",
    "    gifs_clips= []\n",
    "    texto_traducido = traduccion(whisper_text,'English')\n",
    "    words = texto_traducido.split()\n",
    "    \n",
    "    # Group the words into pairs\n",
    "    subtitle_lines = []\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        if i + 3 < len(words) and all(words[j].strip() != '' for j in range(i, i + 4)):\n",
    "            # Si los siguientes cuatro elementos de la lista no están vacíos, unir las cuatro palabras con un espacio\n",
    "            subtitle_lines.append(' '.join([words[i], words[i+1], words[i+2], words[i+3]]))\n",
    "            i += 4\n",
    "        else:\n",
    "            # Si alguno de los siguientes cuatro elementos de la lista está vacío o es el último elemento, agregar solo las palabras actuales\n",
    "            subtitle_lines.append(words[i])\n",
    "            i += 1\n",
    "\n",
    "    # Remove any empty strings from the list of subtitle lines\n",
    "    subtitle_lines = [line.strip() for line in subtitle_lines if line.strip()]\n",
    "\n",
    "    # Create a list to store the text clips\n",
    "    subtitle_clips = []\n",
    "    duration = video.duration / len(subtitle_lines)\n",
    "    # Initialize a variable to keep track of the current line number\n",
    "    line_number = 0\n",
    "    fontsize= 160\n",
    "    # Subtitle Positioning:\n",
    "    subtitle_y = 1800  # Ajusta el valor según tu preferencia\n",
    "    subtitle_position = ('center', subtitle_y)\n",
    "    subtitle_y_shadow = subtitle_y - 8  # Ajusta el valor de sombra para mantener una distancia relativa\n",
    "    subtitle_position_shadow = ('center', subtitle_y_shadow)\n",
    "    # Create a TextClip for each subtitle line and add it to the list\n",
    "    for i, line in enumerate(subtitle_lines):\n",
    "        line = line.upper()\n",
    "  \n",
    "        color = '#FFF444'\n",
    "        subtitle = TextClip(line, fontsize=fontsize,font=\"ProtestStrike-Regular.ttf\", color=color, )\n",
    "        \n",
    "        subtitle_shadow = TextClip(line, fontsize=fontsize+3.9,font=\"ProtestStrike-Regular.ttf\", color= \"black\")\n",
    "\n",
    "        subtitle_clip = subtitle_shadow.set_duration(duration).set_pos(subtitle_position_shadow).set_start(i * duration)\n",
    "        gifs_clips.append(subtitle_clip)\n",
    "        subtitle_clip = subtitle.set_duration(duration).set_pos(subtitle_position).set_start(i * duration)\n",
    "        gifs_clips.append(subtitle_clip)\n",
    "\n",
    "        # Increment the line number\n",
    "        line_number += 1\n",
    "\n",
    "    # Overlay the subtitle clips on the video clip\n",
    "    video_con_superposicion = CompositeVideoClip([video]+ gifs_clips)\n",
    "    video_con_superposicion = video_con_superposicion.set_duration(video.duration)\n",
    "    ffmpeg_params = [\"-vcodec\", \"h264_nvenc\"]  # Utiliza la GPU Nvidia para la codificación de video\n",
    "    \n",
    "    video_con_superposicion.write_videofile(ruta_video_final_editado, codec='libx264', ffmpeg_params=ffmpeg_params)\n",
    "    #video_con_superposicion.write_videofile(ruta_video_final_editado)\n",
    "    del subtitle_lines,duration,texto_traducido,words,video_con_superposicion, gifs_clips\n",
    "    gc.collect()\n",
    "\n",
    "def poner_subtitulos_jap(): \n",
    "    gifs_clips =[]\n",
    "    texto_traducido = traduccion(whisper_text,'Japanese')\n",
    "    words = texto_traducido.split()\n",
    "    \n",
    "    # Group the words into pairs\n",
    "    subtitle_lines = []\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        print(words[i])\n",
    "        if i + 1 < len(words) and words[i+1].strip() != '':\n",
    "            # Si el siguiente elemento de la lista no está vacío, unir las dos palabras con un espacio\n",
    "            subtitle_lines.append(' '.join([words[i], words[i+1]]))\n",
    "            i += 2\n",
    "        else:\n",
    "            # Si el siguiente elemento de la lista está vacío o es el último elemento, agregar solo la palabra actual\n",
    "            subtitle_lines.append(words[i])\n",
    "            i += 1\n",
    "\n",
    "    # Remove any empty strings from the list of subtitle lines\n",
    "    subtitle_lines = [line.strip() for line in subtitle_lines if line.strip()]\n",
    "    \n",
    "    # Create a list to store the text clips\n",
    "    subtitle_clips = []\n",
    "    duration = video.duration / len(subtitle_lines)\n",
    "    # Initialize a variable to keep track of the current line number\n",
    "    line_number = 0\n",
    "    fontsize= 30\n",
    "    # Subtitle Positioning:\n",
    "    subtitle_y = 1080 // 2 + 160  # Ajusta el valor según tu preferencia\n",
    "    subtitle_position = ('center', subtitle_y)\n",
    "    subtitle_y_shadow = subtitle_y - 8  # Ajusta el valor de sombra para mantener una distancia relativa\n",
    "    subtitle_position_shadow = ('center', subtitle_y_shadow)\n",
    "    # Create a TextClip for each subtitle line and add it to the list\n",
    "    for i, line in enumerate(subtitle_lines):\n",
    "        line = line.upper()\n",
    "        color = '#FFF444'\n",
    "        subtitle = TextClip(line, fontsize=fontsize,font=\"humo.ttf\", color=color, )\n",
    "        \n",
    "        subtitle_shadow = TextClip(line, fontsize=fontsize+3.9,font=\"humo.ttf\", color= \"black\")\n",
    "\n",
    "        subtitle_clip = subtitle_shadow.set_duration(duration).set_pos(subtitle_position_shadow).set_start(i * duration)\n",
    "        gifs_clips.append(subtitle_clip)\n",
    "        subtitle_clip = subtitle.set_duration(duration).set_pos(subtitle_position).set_start(i * duration)\n",
    "        gifs_clips.append(subtitle_clip)\n",
    "\n",
    "        # Increment the line number\n",
    "        line_number += 1\n",
    "\n",
    "    # Overlay the subtitle clips on the video clip\n",
    "    video_con_superposicion = CompositeVideoClip([video_final]+ gifs_clips)\n",
    "    video_con_superposicion = video_con_superposicion.set_duration(video_final.duration)\n",
    "    ffmpeg_params = [\"-vcodec\", \"h264_nvenc\"]  # Utiliza la GPU Nvidia para la codificación de video\n",
    "    video_con_superposicion.write_videofile(ruta_video_final_editado, codec='libx264', ffmpeg_params=ffmpeg_params)\n",
    "    #video_con_superposicion.write_videofile(ruta_video_final_editado)\n",
    "    del subtitle_lines,duration,texto_traducido,words,video_con_superposicion, gifs_clips\n",
    "    gc.collect()\n",
    "\n",
    "def poner_intro():\n",
    "        video_path_nuevo = ruta_carpeta_principal + \"//videos_creados//intromorobos.mp4\"\n",
    "        video_nuevo = mpe.VideoFileClip(video_path_nuevo)\n",
    "        video_path_anterior = ruta_video_final_editado\n",
    "        video_anterior = mpe.VideoFileClip(video_path_anterior)\n",
    "        video_concatenado = mpe.concatenate_videoclips([video_nuevo,video_anterior ])\n",
    "        video_concatenado_path = ruta_carpeta_principal + \"//videos_creados//finales//video_finaloso.mp4\"\n",
    "        ffmpeg_params = [\"-vcodec\", \"h264_nvenc\"]  # Utiliza la GPU Nvidia para la codificación de video\n",
    "        video_concatenado.write_videofile(video_concatenado_path, codec='libx264', ffmpeg_params=ffmpeg_params)\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#generar_videos_individuales()\n",
    "#video_largo()\n",
    "video = mp.VideoFileClip(ruta_carpeta_principal + \"//videos_creados//finales//video_final.mp4\")\n",
    "#poner_gif()\n",
    "gifs_clips = []\n",
    "whisper_text = obtener_texto_voz()\n",
    "poner_subtitulos_eng()\n",
    "#poner_intro()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
