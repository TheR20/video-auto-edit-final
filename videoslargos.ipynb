{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formato nuevo txt\n",
    "import re\n",
    "\n",
    "def leer_y_escribir_txt(ruta_archivo_lectura, ruta_archivo_escritura):\n",
    "    try:\n",
    "        with open(ruta_archivo_lectura, \"r\") as archivo_lectura:\n",
    "            lineas = archivo_lectura.readlines()\n",
    "\n",
    "        with open(ruta_archivo_escritura, \"w\") as archivo_escritura:\n",
    "            for linea in lineas:\n",
    "                #linea = re.sub(r'\\-', '', linea)\n",
    "                linea = re.sub(r':', '', linea) \n",
    "                linea = re.sub(r'\"', '', linea)\n",
    "                linea = re.sub(r'ó', 'o', linea)\n",
    "                \n",
    "                # Dividir la línea en segmentos de máximo 239 caracteres y 18 palabras\n",
    "                palabras = linea.split()\n",
    "                contador_palabras = 0\n",
    "                linea_nueva = \"\"\n",
    "                for palabra in palabras:\n",
    "                    if contador_palabras < 18 and len(linea_nueva) + len(palabra) < 239:\n",
    "                        linea_nueva += palabra + \" \"\n",
    "                        contador_palabras += 1\n",
    "                    else:\n",
    "                        archivo_escritura.write(linea_nueva.strip() + \"\\n\")\n",
    "                        contador_palabras = 1\n",
    "                        linea_nueva = palabra + \" \"\n",
    "                \n",
    "                archivo_escritura.write(linea_nueva.strip() + \"\\n\")\n",
    "\n",
    "        print(f\"El archivo se ha escrito correctamente en: {ruta_archivo_escritura}\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Archivo no encontrado: {e.filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inesperado: {e}\")\n",
    "\n",
    "# Ejemplo de uso\n",
    "ruta_archivo_lectura = \"C://Users//R20//Desktop//videostraduccidos//largo_inicial.txt\"\n",
    "ruta_archivo_escritura = \"C://Users//R20//Desktop//videostraduccidos//largo_final.txt\"\n",
    "\n",
    "leer_y_escribir_txt(ruta_archivo_lectura, ruta_archivo_escritura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Definir el patrón regex\n",
    "regex = r\"(?<=^-------------\\n)(.*?)(?=\\n^-------------|$)\"\n",
    "\n",
    "# Leer el archivo de texto\n",
    "with open(\"C://Users//R20//Desktop//videostraduccidos//largo_final.txt\", \"r\", encoding=\"utf-8\") as archivo:\n",
    "    texto_completo = archivo.read()\n",
    "\n",
    "display(texto_completo)\n",
    "\n",
    "lineas_separadas = texto_completo.split(\"-------------\")\n",
    "\n",
    "# Eliminar las líneas vacías\n",
    "lineas_separadas = [linea for linea in lineas_separadas if linea.strip()]\n",
    "\n",
    "# Formatear el resultado en una lista de diccionarios\n",
    "textos_separados = []\n",
    "for texto in lineas_separadas:\n",
    "    textos_separados.append(texto.strip())\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(textos_separados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulo = \"¿El xmen no binario?, \"\n",
    "titulo_texto = \"\"\n",
    "nombre_descargado = \"video29.mp4\" \n",
    "seleccion_voz = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerias y rutas\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from googletrans import Translator\n",
    "from TTS.api import TTS\n",
    "import moviepy.editor as mp\n",
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from moviepy.editor import VideoFileClip, AudioFileClip, TextClip, CompositeVideoClip\n",
    "import moviepy.editor as mpe\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import whisper\n",
    "from IPython.display import Audio, display\n",
    "import pyrubberband\n",
    "import os\n",
    "import gc\n",
    "\n",
    "nombre_audio = \"\"\n",
    "nombre_gifiz = \"\"\n",
    "nombre_gifcen = \"\"\n",
    "nombre_gifder = \"\"\n",
    "\n",
    "if seleccion_voz == 1 :\n",
    "    nombre_audio = \"goth.wav\"\n",
    "    nombre_gifiz = \"//monos//bonitaiz.gif\"\n",
    "    nombre_gifcen = \"//monos//bonitacen.gif\"\n",
    "    nombre_gifder = \"//monos//bonitader.gif\"\n",
    "elif seleccion_voz == 2:\n",
    "    nombre_audio = \"audio_ing_resumen.wav\"\n",
    "    nombre_gifiz = \"//monos//gatomostacho1.gif\"\n",
    "    nombre_gifcen = \"//monos//gatomostacho2.gif\"\n",
    "    nombre_gifder = \"//monos//gatomostacho3.gif\"\n",
    "elif seleccion_voz == 3:\n",
    "    nombre_audio = \"shado.wav\"\n",
    "    nombre_gifiz = \"//monos//peloniz.gif\"\n",
    "    nombre_gifcen = \"//monos//peloncen.gif\"\n",
    "    nombre_gifder = \"//monos//pelonder.gif\"\n",
    "elif seleccion_voz == 4: \n",
    "    nombre_audio = \"ukyo.wav\"\n",
    "    nombre_gifiz = \"//monos//coleiz.gif\"\n",
    "    nombre_gifcen = \"//monos//colecer.gif\"\n",
    "    nombre_gifder = \"//monos//coleder.gif\"\n",
    "elif seleccion_voz == 5:\n",
    "    nombre_audio = \"jira.wav\"\n",
    "    nombre_gifiz = \"//monos//rubiz.gif\"\n",
    "    nombre_gifcen = \"//monos//rubcen.gif\"\n",
    "    nombre_gifder = \"//monos//rubder.gif\"\n",
    "elif seleccion_voz == 6:\n",
    "    nombre_audio = \"bonita.wav\"\n",
    "    nombre_gifiz = \"//monos//bonitaiz.gif\"\n",
    "    nombre_gifcen = \"//monos//bonitacen.gif\"\n",
    "    nombre_gifder = \"//monos//bonitader.gif\"\n",
    "elif seleccion_voz == 7:\n",
    "    nombre_audio = \"boni.wav\"\n",
    "    nombre_gifiz = \"//monos//roryiz.gif\"\n",
    "    nombre_gifcen = \"//monos//rorycen.gif\"\n",
    "    nombre_gifder = \"//monos//roryder.gif\"\n",
    "\n",
    "display(seleccion_voz)\n",
    "display(nombre_audio)\n",
    "\n",
    "\n",
    "rollitas = [\"beach\",\"docerola\",\"final\",\"funkcarioca\",\"hotlanda\",\"huasteco\",\"intro\",\n",
    "            \"mariachi\",\"oaxaca\",\"parade\",\"shake\",\"skyline\",\"takes\",\"wood\"]\n",
    "\n",
    "ruta_carpeta_principal = \"C://Users//R20//Desktop//videostraduccidos//\"\n",
    "ruta_carpeta_audios_esp = \"audios_creados//audio_esp_resumen.wav\"\n",
    "ruta_carpeta_audios_ing = \"audios_creados//\" + nombre_audio\n",
    "ruta_carpeta_audios_fin = \"audios_creados//audio_fin_resumen.wav\"\n",
    "ruta_carpeta_con_musica = \"audios_creados//audio_fin_musica.wav\"\n",
    "temporales = \"audios_creados//temporales//\"\n",
    "musica = \"audios_creados//musica//\"\n",
    "ruta_carpeta_videofin = \"videos_creados//\" + nombre_descargado\n",
    "ruta_carpeta_videofin_editado = \"videos_creados//finales\" + nombre_descargado\n",
    "nombre_video = \"videos_descargados//\" + nombre_descargado\n",
    "\n",
    "rutaVideo = ruta_carpeta_principal + nombre_video\n",
    "ruta_musica =  ruta_carpeta_principal + musica\n",
    "ruta_video_final_editado = ruta_carpeta_principal + ruta_carpeta_videofin_editado\n",
    "rutaAudioIngles = ruta_carpeta_principal + ruta_carpeta_audios_ing\n",
    "rutaAudioGenerado =  ruta_carpeta_principal + ruta_carpeta_audios_esp\n",
    "ruta_audios_temporales = ruta_carpeta_principal + temporales\n",
    "rutaAudioGeneradoNuevaVelocidad = ruta_carpeta_principal + ruta_carpeta_audios_fin\n",
    "rutaAudioGeneradoMusicaFondo = ruta_carpeta_principal +ruta_carpeta_con_musica\n",
    "ruta_video_final = ruta_carpeta_principal + ruta_carpeta_videofin\n",
    "ruta_imagenes = ruta_carpeta_principal + \"imagenes//\"\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar Audio\n",
    "from moviepy.editor import AudioFileClip, concatenate_audioclips\n",
    "archivos_wav=[]\n",
    "duraciones = []\n",
    "def unico_audio():\n",
    "    clips_audio = []\n",
    "    numero_audios = 0\n",
    "    for filename in os.listdir(ruta_audios_temporales):\n",
    "        if filename.endswith((\"wav\")):\n",
    "            numero_audios +=1\n",
    "    for k in range(numero_audios):\n",
    "        ruta_audio_for = ruta_audios_temporales + \"temporal\" + str(k) + \".wav\"\n",
    "        clip = AudioFileClip(ruta_audio_for)\n",
    "        clips_audio.append(clip)\n",
    "        duraciones.append(clip.duration)            \n",
    "    # Concatenar los clips de audio\n",
    "    clip_combinado = concatenate_audioclips(clips_audio)\n",
    "    # Guardar audio combinado\n",
    "    clip_combinado.write_audiofile(rutaAudioGenerado)\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "def auido_generation():\n",
    "    confirmation = input(\"You must confirm the licensing terms. Do you agree? (y/n): \")\n",
    "    if confirmation.lower() != 'y':\n",
    "        print(\"Exiting. License agreement not accepted.\")\n",
    "        exit()\n",
    "\n",
    "    # Crear instancia de TTS\n",
    "    tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(\"cuda\")\n",
    "\n",
    "    vueltas = 0\n",
    "    for parrafo in textos_separados:\n",
    "        # Generar audio\n",
    "        tts.tts_to_file(\n",
    "        textos_separados[vueltas],\n",
    "        speaker_wav=rutaAudioIngles,\n",
    "        file_path=ruta_audios_temporales +\"temporal\"+str(vueltas)+\".wav\",\n",
    "        language=target_language_code,\n",
    "        )\n",
    "        vueltas +=1\n",
    "    gc.collect()\n",
    "        \n",
    "    \n",
    "target_language = \"Spanish\"\n",
    "# Mapping between full names and ISO 639-1 codes\n",
    "language_mapping = {'English': 'en', 'Spanish': 'es', 'Chinese (Simplified)': 'zh-cn', 'Japanese': 'ja'}\n",
    "target_language_code = language_mapping[target_language]\n",
    "subcadenas = []\n",
    "\n",
    "\n",
    "#auido_generation()\n",
    "unico_audio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambiar Velocidad del audio\n",
    "# Cargar un archivo de audio\n",
    "input_audio_file = rutaAudioGenerado\n",
    "\n",
    "stretch_factor =1.5  # Por ejemplo, para aumentar la duración en un 50%\n",
    "\n",
    "# Aplicar el estiramiento del tiempo\n",
    "input_audio_data, sr = sf.read(input_audio_file)\n",
    "output_audio_data = pyrubberband.time_stretch(input_audio_data, sr, rate=stretch_factor)\n",
    "\n",
    "# Guardar el archivo de audio resultante\n",
    "sf.write(rutaAudioGeneradoNuevaVelocidad, output_audio_data, sr)\n",
    "\n",
    "audio_widget = Audio(filename=rutaAudioGeneradoNuevaVelocidad, autoplay=False)\n",
    "display(audio_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poner musica de fondo\n",
    "from pydub import AudioSegment\n",
    "\n",
    "\n",
    "random_number = np.random.randint(0, 14)\n",
    "# Cargar los audios\n",
    "audio = AudioSegment.from_wav(rutaAudioGeneradoNuevaVelocidad)\n",
    "music = AudioSegment.from_wav(ruta_musica + rollitas[random_number] + \".wav\")\n",
    "\n",
    "max_amplitude = audio.max_dBFS\n",
    "max_music = music.max_dBFS\n",
    "display(max_amplitude)\n",
    "display(max_music)\n",
    "display(str(random_number) + \" - \" + str(rollitas[random_number]))\n",
    "\n",
    "# Obtener la duración del audio y de la música\n",
    "duracion_audio = len(audio) / 1000  # Duración en segundos\n",
    "duracion_musica = len(music) / 1000  # Duración en segundos\n",
    "\n",
    "# Calcular cuántas veces se debe repetir la música para igualar la duración del audio\n",
    "repeticiones = int(duracion_audio / duracion_musica) + 1\n",
    "\n",
    "# Repetir la música\n",
    "music_repetida = music * repeticiones\n",
    "\n",
    "# Cortar la música para que tenga la misma duración que el audio\n",
    "music_cortada = music_repetida[:len(audio)]\n",
    "\n",
    "# Adjust the volume of the music (optional)\n",
    "if(max_amplitude <= -1):\n",
    "    audio_scaled = audio - .50\n",
    "    display(\"holi\")\n",
    "music_scaled = music_cortada - 25\n",
    "\n",
    "# Overlay the audio and music\n",
    "audio_mixed = audio.overlay(music_scaled)\n",
    "\n",
    "# Save the mixed audio\n",
    "audio_mixed.export(rutaAudioGeneradoMusicaFondo, format=\"wav\")\n",
    "\n",
    "audio_widget = Audio(filename=rutaAudioGeneradoMusicaFondo, autoplay=False)\n",
    "display(audio_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#videos individuales, largo, gif y subtitulado.\n",
    "import imageio\n",
    "import random\n",
    "\n",
    "\n",
    "numero_audios = 0\n",
    "video = None \n",
    "\n",
    "gifs_clips = []\n",
    "for filename in os.listdir(ruta_audios_temporales):\n",
    "     if filename.endswith((\"wav\")):\n",
    "         numero_audios +=1\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "def animacion_lateral(image,iteraciones_for,n_segundos,n_frames,duration_original):\n",
    "    # Estirar la imagen (ejemplo: duplicar su ancho)\n",
    "        image = image.resize((image.width , image.height ))\n",
    "\n",
    "        # Convertir a formato compatible con OpenCV\n",
    "        image_opencv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGRA)\n",
    "\n",
    "        # Crear la animación\n",
    "        alto, ancho, _ = image_opencv.shape\n",
    "        if iteraciones_for % 2 == 0:\n",
    "            matriz_transformacion = np.array([[2, 0, -image.width], [0, 1, 1]], dtype=np.float32)\n",
    "        else:\n",
    "            matriz_transformacion = np.array([[2, 0, 1], [0, 1, 1]], dtype=np.float32)\n",
    "        frames = []\n",
    "        pixeles_por_segundo = image.width / n_segundos\n",
    "        pixeles_por_frame = pixeles_por_segundo/n_frames\n",
    "        \n",
    "        for i in range(int(n_segundos*n_frames)):\n",
    "            imagen_transformada = cv2.warpAffine(image_opencv, matriz_transformacion, (ancho, alto))\n",
    "            # Convertir de BGR a RGB para mantener los colores originales\n",
    "            imagen_transformada = cv2.cvtColor(imagen_transformada, cv2.COLOR_BGRA2RGB)\n",
    "            frames.append(imagen_transformada)\n",
    "            if iteraciones_for % 2 == 0:\n",
    "                matriz_transformacion[0, 2] += pixeles_por_frame\n",
    "            else:\n",
    "                matriz_transformacion[0, 2] -= pixeles_por_frame\n",
    "\n",
    "        # Crear el clip de video con la animación\n",
    "        videok = mpe.ImageSequenceClip(frames, fps=30).set_duration(duration_original / 1.5)\n",
    "        return videok\n",
    "def animacion_zoom(duration_original,fr,imagen,iteraciones_for):\n",
    "    image = imageio.imread(imagen)\n",
    "    image_opencv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGRA)\n",
    "    n_frames = int(duration_original * fr)\n",
    "    alto, ancho, _ = image.shape\n",
    "    frames = []\n",
    "    # Calcular la escala inicial y final para que la animación dure todo el tiempo del video\n",
    "    if iteraciones_for % 2 == 0:\n",
    "        escala_inicial = 1\n",
    "        escala_final = 2\n",
    "    else:\n",
    "        escala_inicial = 2\n",
    "        escala_final = 1\n",
    "\n",
    "    for i in range(n_frames):\n",
    "        # Calcular la escala actual en función del progreso del video\n",
    "        progreso = i / n_frames\n",
    "        escala_actual = escala_inicial + (escala_final - escala_inicial) * progreso\n",
    "        \n",
    "        # Aplicar la transformación de escala\n",
    "        matriz_transformacion = cv2.getRotationMatrix2D((ancho/2, alto/2), 0, escala_actual)\n",
    "        imagen_transformada = cv2.warpAffine(image, matriz_transformacion, (ancho, alto))\n",
    "        \n",
    "        # Crear el borde negro para mantener el tamaño del video\n",
    "        borde_negro = np.zeros((imagen_transformada.shape[0], 10, 4), dtype=np.uint8)\n",
    "        imagen_con_borde = np.concatenate((imagen_transformada, borde_negro), axis=1)\n",
    "        frames.append(imagen_con_borde)\n",
    "\n",
    "    # Crear el clip de video con la secuencia de imágenes y establecer la duración\n",
    "    clip = mpe.ImageSequenceClip(frames, fps=fr).set_duration(duration_original / 1.5)\n",
    "    return clip\n",
    "\n",
    "def generar_videos_individuales():\n",
    "    display(numero_audios)\n",
    "    iteraciones_for = 2\n",
    "    n_frames = 30\n",
    "    random_anterior = 0\n",
    "    for y in range(numero_audios):\n",
    "        ruta_audio_for = ruta_audios_temporales + \"temporal\" + str(y) + \".wav\"\n",
    "        ruta_imagen_for = ruta_imagenes + str(y+1)+ \".png\"\n",
    "        y_generated, sr_generated = librosa.load(ruta_audio_for)\n",
    "        duration_original = len(y_generated) / sr_generated\n",
    "        n_segundos = duration_original\n",
    "        iteraciones_for +=1\n",
    "        # Cargar la imagen\n",
    "        image = Image.open(ruta_imagen_for)\n",
    "\n",
    "        numero_random = random.randint(1, 4)\n",
    "        while numero_random == random_anterior:\n",
    "            numero_random = random.randint(1, 4)\n",
    "        random_anterior = numero_random\n",
    "        if numero_random == 1 or numero_random == 2:\n",
    "            video = animacion_lateral(image,numero_random,n_segundos,n_frames,duration_original)\n",
    "        else:\n",
    "            video = animacion_zoom(duration_original,n_frames,ruta_imagen_for,numero_random)\n",
    "        #video = clip.set_audio(mpe.AudioFileClip(ruta_audio_for))\n",
    "\n",
    "        video.fps = 30  # Ajusta el frame rate\n",
    "\n",
    "        video = video.resize((1920, 1080))  # Dimensiones Full HD\n",
    "        video_path = ruta_carpeta_principal + \"//videos_creados//finales//temporal\" + str(y) + \".mp4\"\n",
    "        if ((y + 1) % 3 == 0 or y == 0 ) and y != numero_audios:\n",
    "            texto_completo = textos_separados[y]  # Texto que deseas mostrar\n",
    "            mitad = len(texto_completo) // 2\n",
    "            indice_espacio_mas_cercano = texto_completo.rfind(\" \", 0, mitad)  # Busca el espacio más cercano a la mitad\n",
    "            if indice_espacio_mas_cercano == -1:  # Si no se encontró ningún espacio, usar la mitad como punto de división\n",
    "                indice_espacio_mas_cercano = mitad\n",
    "            primera_parte = texto_completo[:indice_espacio_mas_cercano]\n",
    "            segunda_parte = texto_completo[indice_espacio_mas_cercano:].strip()\n",
    "            texto_con_salto_de_linea = f\"{primera_parte}\\n{segunda_parte}\"\n",
    "            fontsize = 65\n",
    "            posicion = (\"center\")\n",
    "            subtitle = mpe.TextClip(texto_con_salto_de_linea, fontsize=fontsize, font=\"ProtestStrike-Regular.ttf\", color='white', bg_color='black')\n",
    "            subtitle_clip = subtitle.set_pos(posicion).set_duration(duration_original / 1.5)\n",
    "            videos = mpe.CompositeVideoClip([video, subtitle_clip])\n",
    "            ffmpeg_params = [\"-vcodec\", \"h264_nvenc\"]  # Utiliza la GPU Nvidia para la codificación de video\n",
    "            videos.write_videofile(video_path, codec='libx264', ffmpeg_params=ffmpeg_params)\n",
    "            #videos.write_videofile(video_path)\n",
    "        else:\n",
    "            ffmpeg_params = [\"-vcodec\", \"h264_nvenc\"]  # Utiliza la GPU Nvidia para la codificación de video\n",
    "            video.write_videofile(video_path, codec='libx264', ffmpeg_params=ffmpeg_params)\n",
    "        \n",
    "            #video.write_videofile(video_path)\n",
    "        \n",
    "        del y_generated, sr_generated, duration_original, image, video\n",
    "        gc.collect()  # Llamar al recolector de basura de Python para liberar memoria adicional\n",
    "\n",
    "def video_largo():\n",
    "    video_concatenado = None\n",
    "    for y in range(numero_audios):\n",
    "        if(y != 0):\n",
    "            video_path_nuevo = ruta_carpeta_principal + \"//videos_creados//finales//temporal\" + str(y) + \".mp4\"\n",
    "            video_nuevo = mpe.VideoFileClip(video_path_nuevo)\n",
    "\n",
    "            # Concatenar los dos videos\n",
    "            if y == 1:\n",
    "                video_path_anterior = ruta_carpeta_principal + \"//videos_creados//finales//temporal\" + str(y-1) + \".mp4\"\n",
    "                video_anterior = mpe.VideoFileClip(video_path_anterior)\n",
    "                video_concatenado = mpe.concatenate_videoclips([video_anterior, video_nuevo])\n",
    "            else:\n",
    "                video_concatenado = mpe.concatenate_videoclips([video_concatenado, video_nuevo])\n",
    "        gc.collect()\n",
    "    # Agregar el audio al video concatenado\n",
    "    video_concatenado_with_audio = video_concatenado.set_audio(mpe.AudioFileClip(rutaAudioGeneradoMusicaFondo))\n",
    "\n",
    "    # Guardar el video concatenado con audio\n",
    "    video_concatenado_path = ruta_carpeta_principal + \"//videos_creados//finales//video_final.mp4\"\n",
    "    ffmpeg_params = [\"-vcodec\", \"h264_nvenc\"]  # Utiliza la GPU Nvidia para la codificación de video\n",
    "    video_concatenado_with_audio.write_videofile(video_concatenado_path, codec='libx264', ffmpeg_params=ffmpeg_params)\n",
    "    #video_concatenado_with_audio.write_videofile(video_concatenado_path)\n",
    "    # Liberar recursos\n",
    "    gc.collect()\n",
    "\n",
    "def poner_gif():\n",
    "        #Generar letreros en el video.\n",
    "    \n",
    "    #imagen = (mpe.ImageClip(ruta_imagenes + \"conocidas//patito.gif\")\n",
    "    imagen = (mpe.VideoFileClip(ruta_imagenes + \"conocidas//\"+nombre_gifiz, has_mask=True)         \n",
    "            .resize((800, 600))\n",
    "            .set_duration(8)\n",
    "                )  # Establecer la duración de la imagen a 3 segundos\n",
    "    imagen_final = (mpe.VideoFileClip(ruta_imagenes + \"conocidas//\"+nombre_gifcen, has_mask=True)         \n",
    "            .resize((800, 600))\n",
    "            .set_duration(8)\n",
    "                )\n",
    "    imagen_medio = (mpe.VideoFileClip(ruta_imagenes + \"conocidas//\"+nombre_gifder, has_mask=True)         \n",
    "            .resize((800, 600))\n",
    "            .set_duration(8)\n",
    "                )\n",
    "\n",
    "    random_number = np.random.randint(1, 5)\n",
    "    if random_number == 1:\n",
    "        clip_inicio = imagen.set_pos(\"center\")#((-250, 750))\n",
    "        clip_final = imagen_final.set_start(video.duration - 30).set_pos(\"center\")\n",
    "        clip_medio = imagen_medio.set_start(video.duration//2 - 1).set_pos(\"center\")\n",
    "    elif random_number == 2:\n",
    "        clip_inicio = imagen.set_pos(\"center\")\n",
    "        clip_final = imagen_medio.set_start(video.duration - 30).set_pos(\"center\")\n",
    "        clip_medio = imagen_final.set_start(video.duration//2 - 1).set_pos(\"center\")\n",
    "    elif random_number == 3:\n",
    "        clip_inicio = imagen_medio.set_pos(\"center\")\n",
    "        clip_final = imagen.set_start(video.duration - 30).set_pos(\"center\")\n",
    "        clip_medio = imagen_final.set_start(video.duration//2 - 1).set_pos(\"center\")\n",
    "    elif random_number == 4:\n",
    "        clip_inicio = imagen_final.set_pos(\"center\")\n",
    "        clip_final = imagen.set_start(video.duration - 30).set_pos(\"center\")\n",
    "        clip_medio = imagen_medio.set_start(video.duration//2 - 1).set_pos(\"center\")\n",
    "\n",
    "\n",
    "\n",
    "    superposicion = clip_inicio\n",
    "    superposicion2 = clip_final\n",
    "    superposicion3 = clip_medio\n",
    "\n",
    "\n",
    "    gifs_clips.append(superposicion)\n",
    "    gifs_clips.append(superposicion2)\n",
    "    gifs_clips.append(superposicion3)\n",
    "    display(\"Termine de poner los gifs\")\n",
    "    gc.collect()\n",
    "\n",
    "def poner_imagenes(nombre_imagen, inicio):\n",
    "    #Cargar la imagen y redimensionarla\n",
    "    imagen = (mpe.ImageClip(ruta_imagenes + \"conocidas//\"+nombre_imagen+\".png\")\n",
    "            .resize((400, 300))\n",
    "            .set_duration(1)\n",
    "            .set_start(inicio)\n",
    "            )  # Establecer la duración de la imagen a 3 segundos\n",
    "\n",
    "    ancho_video, alto_video = video.size\n",
    "\n",
    "    # Calcular las coordenadas del centro\n",
    "    x_centro = ancho_video / 2 - imagen.w / 2\n",
    "    y_centro = alto_video / 2 - imagen.h / 2\n",
    "\n",
    "    superposicion = imagen.set_pos((x_centro, y_centro))\n",
    "    return superposicion\n",
    "\n",
    "def no_subtitulos():\n",
    "    palabras_clave = [\"STEAM\",\"XBOX\",\"NINTENDO\",\"MARVEL\",\"UCM\",\"DC\",\"DCEU\",\"NETFLIX\",\"NICK\"]  # Ajusta según tus necesidades\n",
    "    with open(\"C://Users//R20//Desktop//videostraduccidos//largo_final.txt\", \"r\", encoding=\"utf-8\") as archivo:\n",
    "        new_text_trans = archivo.read()\n",
    "    whisper_text = new_text_trans.replace('.', '. ').replace('?', '? ')\n",
    "\n",
    "    words = whisper_text.split()\n",
    "\n",
    "    # Group the words into pairs\n",
    "    #subtitle_lines = [' '.join(words[i:i+2]) for i in range(0, len(words), 2)]\n",
    "    subtitle_lines = []\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        if i + 1 < len(words) and words[i+1].strip() != '':\n",
    "            # Si el siguiente elemento de la lista no está vacío, unir las dos palabras con un espacio\n",
    "            subtitle_lines.append(' '.join([words[i], words[i+1]]))\n",
    "            i += 2\n",
    "        else:\n",
    "            # Si el siguiente elemento de la lista está vacío o es el último elemento, agregar solo la palabra actual\n",
    "            subtitle_lines.append(words[i])\n",
    "            i += 1\n",
    "\n",
    "    # Remove any empty strings from the list of subtitle lines\n",
    "    subtitle_lines = [line.strip() for line in subtitle_lines if line.strip()]\n",
    "    # Create a list to store the text clips\n",
    "    duration = video.duration / len(subtitle_lines)\n",
    "    # Initialize a variable to keep track of the current line number\n",
    "    line_number = 0\n",
    "    \n",
    "    \n",
    "    for i, line in enumerate(subtitle_lines):\n",
    "        if any(palabra in line for palabra in palabras_clave):\n",
    "            # Encontrar la primera palabra clave en la línea\n",
    "            for palabra in palabras_clave:\n",
    "                if palabra in line:\n",
    "                    palabra_clave_encontrada = palabra\n",
    "                    break\n",
    "\n",
    "            display(palabra_clave_encontrada)\n",
    "            superposicion = poner_imagenes(palabra_clave_encontrada, i * duration)\n",
    "            gifs_clips.append(superposicion)\n",
    "        # Increment the line number\n",
    "        line_number += 1\n",
    "    # Overlay the subtitle clips on the video clip\n",
    "    video_con_superposicion = CompositeVideoClip([video]+ gifs_clips)\n",
    "    video_con_superposicion = video_con_superposicion.set_duration(video.duration)\n",
    "    ffmpeg_params = [\"-vcodec\", \"h264_nvenc\"]  # Utiliza la GPU Nvidia para la codificación de video\n",
    "    video_con_superposicion.write_videofile(ruta_video_final_editado, codec='libx264', ffmpeg_params=ffmpeg_params)\n",
    "    #video_con_superposicion.write_videofile(ruta_video_final_editado)\n",
    "    gc.collect()\n",
    "   \n",
    "def poner_subtitulos():\n",
    "    palabras_clave = [\"STEAM\",\"XBOX\",\"NINTENDO\",\"MARVEL\",\"UCM\",\"DC\",\"DCEU\",\"NETFLIX\",\"NICK\"]  # Ajusta según tus necesidades\n",
    "    with open(\"C://Users//R20//Desktop//videostraduccidos//largo_final.txt\", \"r\", encoding=\"utf-8\") as archivo:\n",
    "        new_text_trans = archivo.read()\n",
    "    whisper_text = new_text_trans.replace('.', '. ').replace('?', '? ')\n",
    "\n",
    "    words = whisper_text.split()\n",
    "\n",
    "    # Group the words into pairs\n",
    "    #subtitle_lines = [' '.join(words[i:i+2]) for i in range(0, len(words), 2)]\n",
    "    subtitle_lines = []\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        if i + 1 < len(words) and words[i+1].strip() != '':\n",
    "            # Si el siguiente elemento de la lista no está vacío, unir las dos palabras con un espacio\n",
    "            subtitle_lines.append(' '.join([words[i], words[i+1]]))\n",
    "            i += 2\n",
    "        else:\n",
    "            # Si el siguiente elemento de la lista está vacío o es el último elemento, agregar solo la palabra actual\n",
    "            subtitle_lines.append(words[i])\n",
    "            i += 1\n",
    "\n",
    "    # Remove any empty strings from the list of subtitle lines\n",
    "    subtitle_lines = [line.strip() for line in subtitle_lines if line.strip()]\n",
    "\n",
    "    # Create a list to store the text clips\n",
    "    subtitle_clips = []\n",
    "\n",
    "    # Set the font size and duration for each subtitle line\n",
    "    fontsize = 85\n",
    "    # Register the font\n",
    "    #font = ImageFont.truetype(\"Bubblegum.ttf\", fontsize)\n",
    "    duration = video.duration / len(subtitle_lines)\n",
    "\n",
    "    # Initialize a variable to keep track of the current line number\n",
    "    line_number = 0\n",
    "    \n",
    "    # Subtitle Positioning:\n",
    "    subtitle_y = 1080 // 2 + 60  # Ajusta el valor según tu preferencia\n",
    "    subtitle_position = ('center', subtitle_y)\n",
    "    subtitle_y_shadow = subtitle_y - 12  # Ajusta el valor de sombra para mantener una distancia relativa\n",
    "    subtitle_position_shadow = ('center', subtitle_y_shadow)\n",
    "    # Create a TextClip for each subtitle line and add it to the list\n",
    "    for i, line in enumerate(subtitle_lines):\n",
    "        line = line.upper()\n",
    "        if line_number % 3 == 0:\n",
    "            color = '#FF0000'\n",
    "        elif line_number % 3 == 1:\n",
    "            color = '#FFF444'\n",
    "        else:\n",
    "            color = 'white'\n",
    "        subtitle = TextClip(line, fontsize=fontsize,font=\"ProtestStrike-Regular.ttf\", color=color, )\n",
    "        \n",
    "        subtitle_shadow = TextClip(line, fontsize=fontsize+3.9,font=\"ProtestStrike-Regular.ttf\", color= \"black\")\n",
    "        if any(palabra in line for palabra in palabras_clave):\n",
    "            # Encontrar la primera palabra clave en la línea\n",
    "            for palabra in palabras_clave:\n",
    "                if palabra in line:\n",
    "                    palabra_clave_encontrada = palabra\n",
    "                    break\n",
    "\n",
    "            display(palabra_clave_encontrada)\n",
    "            \n",
    "            subtitle_clip = subtitle_shadow.set_duration(duration).set_pos(subtitle_position_shadow).set_start(i * duration)\n",
    "            gifs_clips.append(subtitle_clip)\n",
    "            subtitle_clip = subtitle.set_duration(duration).set_pos(subtitle_position).set_start(i * duration)\n",
    "            gifs_clips.append(subtitle_clip)\n",
    "            superposicion = poner_imagenes(palabra_clave_encontrada, i * duration)\n",
    "            gifs_clips.append(superposicion)\n",
    "        #else:\n",
    "            subtitle_clip = subtitle_shadow.set_duration(duration).set_pos(subtitle_position_shadow).set_start(i * duration)\n",
    "            gifs_clips.append(subtitle_clip)\n",
    "            subtitle_clip = subtitle.set_duration(duration).set_pos(subtitle_position).set_start(i * duration)\n",
    "            gifs_clips.append(subtitle_clip)\n",
    "\n",
    "        # Increment the line number\n",
    "        line_number += 1\n",
    "    # Overlay the subtitle clips on the video clip\n",
    "    video_con_superposicion = CompositeVideoClip([video]+ gifs_clips)\n",
    "    video_con_superposicion = video_con_superposicion.set_duration(video.duration)\n",
    "    ffmpeg_params = [\"-vcodec\", \"h264_nvenc\"]  # Utiliza la GPU Nvidia para la codificación de video\n",
    "    video_con_superposicion.write_videofile(ruta_video_final_editado, codec='libx264', ffmpeg_params=ffmpeg_params)\n",
    "    #video_con_superposicion.write_videofile(ruta_video_final_editado)\n",
    "    gc.collect()\n",
    "\n",
    "def poner_intro():\n",
    "        video_path_nuevo = ruta_carpeta_principal + \"//videos_creados//intromorobos.mp4\"\n",
    "        video_nuevo = mpe.VideoFileClip(video_path_nuevo)\n",
    "        video_path_anterior = ruta_video_final_editado\n",
    "        video_anterior = mpe.VideoFileClip(video_path_anterior)\n",
    "        outro = ruta_carpeta_principal + \"//videos_creados//intromorobos.mp4\"\n",
    "        video_outro = mpe.VideoFileClip(outro)\n",
    "        video_concatenado = mpe.concatenate_videoclips([video_nuevo, video_anterior])\n",
    "        video_concatenad2 = mpe.concatenate_videoclips([video_concatenado, video_outro])\n",
    "        video_concatenado_path = ruta_carpeta_principal + \"//videos_creados//finales//video_finaloso.mp4\"\n",
    "        ffmpeg_params = [\"-vcodec\", \"h264_nvenc\"]  # Utiliza la GPU Nvidia para la codificación de video\n",
    "        video_concatenad2.write_videofile(video_concatenado_path, codec='libx264', ffmpeg_params=ffmpeg_params)\n",
    "\n",
    "\n",
    "#generar_videos_individuales()\n",
    "#video_largo()\n",
    "video = mp.VideoFileClip(ruta_carpeta_principal + \"//videos_creados//finales//video_final.mp4\")\n",
    "poner_gif()\n",
    "#poner_subtitulos()\n",
    "#no_subtitulos\n",
    "poner_intro()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
